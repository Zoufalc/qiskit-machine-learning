{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# qGANs for Loading Random Distributions\n",
    "\n",
    "Given $k$-dimensional data samples, we employ a quantum Generative Adversarial Network (qGAN) to learn the data's underlying random distribution and to load it directly into a quantum state:\n",
    "\n",
    "$$ \\big| g_{\\theta}\\rangle = \\sum_{j=0}^{2^n-1} \\sqrt{p_{\\theta}^{j}}\\big| j \\rangle $$\n",
    "\n",
    "where $p_{\\theta}^{j}$ describe the occurrence probabilities of the basis states $\\big| j\\rangle$. \n",
    "\n",
    "The aim of the qGAN training is to generate a state $\\big| g_{\\theta}\\rangle$ where $p_{\\theta}^{j}$, for $j\\in \\left\\{0, \\ldots, {2^n-1} \\right\\}$, describe a probability distribution that is close to the distribution underlying the training data $X=\\left\\{x^0, \\ldots, x^{k-1} \\right\\}$.\n",
    "\n",
    "For further details please refer to [Quantum Generative Adversarial Networks for Learning and Loading Random Distributions](https://arxiv.org/abs/1904.00043) _Zoufal, Lucchi, Woerner_ \\[2019\\].\n",
    "\n",
    "For an example of how to use a trained qGAN in an application, the pricing of financial derivatives, please see the\n",
    "[Option Pricing with qGANs](https://github.com/Qiskit/qiskit-finance/tree/main/docs/tutorials/10_qgan_option_pricing.ipynb) tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'BaseBackend' from 'qiskit.providers' (/Users/ouf/Documents/Github/terra_ouf/qiskit/providers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-abc19f54e9ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumInstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm_globals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNumPyDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mQGAN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPyTorchDiscriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0malgorithm_globals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/qiskit-machine-learning/qiskit_machine_learning/algorithms/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m \"\"\"\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mtrainable_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTrainableModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mserializable_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSerializableModelMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m from .objective_functions import (\n",
      "\u001b[0;32m~/Documents/Github/qiskit-machine-learning/qiskit_machine_learning/algorithms/trainable_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQiskitMachineLearningError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit_machine_learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneural_networks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m from qiskit_machine_learning.utils.loss_functions import (\n\u001b[1;32m     24\u001b[0m     \u001b[0mLoss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/qiskit-machine-learning/qiskit_machine_learning/neural_networks/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \"\"\"\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcircuit_qnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCircuitQNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mopflow_qnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOpflowQNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/qiskit-machine-learning/qiskit_machine_learning/neural_networks/circuit_qnn.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCircuitSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mStateFn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOpflowError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperatorBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseBackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mqiskit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mQuantumInstance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'BaseBackend' from 'qiskit.providers' (/Users/ouf/Documents/Github/terra_ouf/qiskit/providers/__init__.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "seed = 71\n",
    "np.random.seed = seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from qiskit import QuantumRegister, QuantumCircuit, BasicAer\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit_machine_learning.algorithms import NumPyDiscriminator, QGAN, PyTorchDiscriminator\n",
    "\n",
    "algorithm_globals.random_seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Training Data\n",
    "\n",
    "First, we need to load the $k$-dimensional training data samples (here k=1).\n",
    "\n",
    "Next, the data resolution is set, i.e. the min/max data values and the number of qubits used to represent each data dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number training data samples\n",
    "# N = 10000\n",
    "N = 1000\n",
    "\n",
    "# Load data samples from log-normal distribution with mean=1 and standard deviation=1\n",
    "mu = 1\n",
    "sigma = 1\n",
    "real_data = np.random.lognormal(mean=mu, sigma=sigma, size=N)\n",
    "\n",
    "# Set the data resolution\n",
    "# Set upper and lower data values as list of k min/max data values [[min_0,max_0],...,[min_k-1,max_k-1]]\n",
    "bounds = np.array([0.0, 3.0])\n",
    "# Set number of qubits per data dimension as list of k qubit values[#q_0,...,#q_k-1]\n",
    "num_qubits = [2]\n",
    "k = len(num_qubits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the qGAN\n",
    "\n",
    "The qGAN consists of a quantum generator $G_{\\theta}$, i.e., an ansatz, and a classical discriminator $D_{\\phi}$, a neural network.\n",
    "\n",
    "To implement the quantum generator, we choose a depth-$1$ ansatz that implements $R_Y$ rotations and $CZ$ gates which takes a uniform distribution as an input state. Notably, for $k>1$ the generator's parameters must be chosen carefully. For example, the circuit depth should be $>1$ because higher circuit depths enable the representation of more complex structures.\n",
    "\n",
    "The classical discriminator used here is based on a neural network implementation using NumPy. There is also a discriminator based on PyTorch which is not installed by default when installing Qiskit - see [Optional Install](https://github.com/Qiskit/qiskit-machine-learning#optional-installs) for more information.\n",
    "\n",
    "Here, both networks are updated with the ADAM optimization algorithm (ADAM is qGAN optimizer default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of training epochs\n",
    "# Note: The algorithm's runtime can be shortened by reducing the number of training epochs.\n",
    "num_epochs = 10 * 2\n",
    "# Batch size\n",
    "# batch_size = 5800\n",
    "batch_size = 100\n",
    "\n",
    "# Set quantum instance to run the quantum generator\n",
    "# quantum_instance = QuantumInstance(\n",
    "#     backend=BasicAer.get_backend(\"statevector_simulator\"), seed_transpiler=seed, seed_simulator=seed\n",
    "# )\n",
    "quantum_instance = QuantumInstance(\n",
    "    backend=BasicAer.get_backend(\"qasm_simulator\")\n",
    "    , seed_transpiler=seed, seed_simulator=seed\n",
    ")\n",
    "\n",
    "backend = BasicAer.get_backend(\"qasm_simulator\")\n",
    "\n",
    "# Initialize qGAN\n",
    "qgan = QGAN(real_data, bounds, num_qubits, batch_size, num_epochs, snapshot_dir=None, quantum_instance=quantum_instance)\n",
    "qgan.seed = 1\n",
    "\n",
    "\n",
    "# Set entangler map\n",
    "entangler_map = [[0, 1]]\n",
    "\n",
    "\n",
    "# Set an initial state for the generator circuit as a uniform distribution\n",
    "# This corresponds to applying Hadamard gates on all qubits\n",
    "init_dist = QuantumCircuit(sum(num_qubits))\n",
    "init_dist.h(init_dist.qubits)\n",
    "\n",
    "# Set the ansatz circuit\n",
    "ansatz = TwoLocal(int(np.sum(num_qubits)), \"ry\", \"cz\", entanglement=entangler_map, reps=1)\n",
    "\n",
    "# Set generator's initial parameters - in order to reduce the training time and hence the\n",
    "# total running time for this notebook\n",
    "init_params = [3.0, 1.0, 0.6, 1.6]\n",
    "\n",
    "# You can increase the number of training epochs and use random initial parameters.\n",
    "# init_params = np.random.rand(ansatz.num_parameters_settable) * 2 * np.pi\n",
    "\n",
    "# Set generator circuit by adding the initial distribution infront of the ansatz\n",
    "g_circuit = ansatz.compose(init_dist, front=True)\n",
    "\n",
    "from qiskit.algorithms.optimizers import ADAM, COBYLA\n",
    "# optimizer = ADAM(\n",
    "#                 maxiter=1,\n",
    "#                 tol=1e-6,\n",
    "#                 lr=1e-2,\n",
    "#                 beta_1=0.7,\n",
    "#                 beta_2=0.99,\n",
    "#                 noise_factor=1e-5,\n",
    "#                 eps=1e-3,\n",
    "#                 amsgrad=True,\n",
    "#             )\n",
    "\n",
    "# optimizer = ADAM(\n",
    "#                 maxiter=1,\n",
    "#                 tol=1e-6,\n",
    "#                 lr=1e-3,\n",
    "#                 beta_1=0.7,\n",
    "#                 beta_2=0.99,\n",
    "#                 noise_factor=1e-6,\n",
    "#                 eps=1e-6,\n",
    "#                 amsgrad=True,\n",
    "#             )\n",
    "\n",
    "optimizer = COBYLA(maxiter=1)\n",
    "\n",
    "from qiskit.opflow import Gradient\n",
    "\n",
    "# custom_grad = Gradient(\"fin_diff\")\n",
    "custom_grad = Gradient(\"param_shift\")\n",
    "\n",
    "# Set quantum generator\n",
    "qgan.set_generator(generator_circuit=g_circuit, generator_init_params=init_params,\n",
    "                   # generator_optimizer = optimizer,\n",
    "                   generator_gradient=custom_grad\n",
    "                   )\n",
    "# The parameters have an order issue that following is a temp. workaround\n",
    "qgan._generator._free_parameters = sorted(g_circuit.parameters, key=lambda p: p.name)\n",
    "# Set classical discriminator neural network\n",
    "# discriminator = NumPyDiscriminator(len(num_qubits))\n",
    "discriminator = PyTorchDiscriminator(len(num_qubits))\n",
    "qgan.set_discriminator(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the qGAN Training\n",
    "\n",
    "During the training the discriminator's and the generator's parameters are updated alternately w.r.t the following loss functions:\n",
    "$$ L_G\\left(\\phi, \\theta\\right) = -\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log\\left(D_{\\phi}\\left(g^{l}\\right)\\right)\\right] $$\n",
    "and\n",
    "$$  L_D\\left(\\phi, \\theta\\right) =\n",
    "\t\\frac{1}{m}\\sum\\limits_{l=1}^{m}\\left[\\log D_{\\phi}\\left(x^{l}\\right) + \\log\\left(1-D_{\\phi}\\left(g^{l}\\right)\\right)\\right], $$\n",
    "with $m$ denoting the batch size and $g^l$ describing the data samples generated by the quantum generator.\n",
    "\n",
    "Please note that the training, for the purpose of this notebook, has been kept briefer by the selection of a known initial point (`init_params`). Without such prior knowledge be aware training may take some while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run qGAN\n",
    "result = qgan.run(quantum_instance)\n",
    "# result = qgan.run(backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training results:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"  {key} : {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Progress & Outcome\n",
    "\n",
    "Now, we plot the evolution of the generator's and the discriminator's loss functions during the training, as well as the progress in the relative entropy between the trained and the target distribution.\n",
    "\n",
    "Finally, we also compare the cumulative distribution function (CDF) of the trained distribution to the CDF of the target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot progress w.r.t the generator's and the discriminator's loss function\n",
    "t_steps = np.arange(num_epochs)\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Progress in the loss function\")\n",
    "plt.plot(\n",
    "    t_steps, qgan.g_loss, label=\"Generator loss function\", color=\"mediumvioletred\", linewidth=2\n",
    ")\n",
    "plt.plot(\n",
    "    t_steps, qgan.d_loss, label=\"Discriminator loss function\", color=\"rebeccapurple\", linewidth=2\n",
    ")\n",
    "plt.grid()\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"time steps\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot progress w.r.t relative entropy\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"Relative Entropy\")\n",
    "plt.plot(\n",
    "    np.linspace(0, num_epochs, len(qgan.rel_entr)), qgan.rel_entr, color=\"mediumblue\", lw=4, ls=\":\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.xlabel(\"time steps\")\n",
    "plt.ylabel(\"relative entropy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbsphinx-thumbnail"
    ]
   },
   "outputs": [],
   "source": [
    "# Plot the CDF of the resulting distribution against the target distribution, i.e. log-normal\n",
    "log_normal = np.random.lognormal(mean=1, sigma=1, size=100000)\n",
    "log_normal = np.round(log_normal)\n",
    "log_normal = log_normal[log_normal <= bounds[1]]\n",
    "temp = []\n",
    "for i in range(int(bounds[1] + 1)):\n",
    "    temp += [np.sum(log_normal == i)]\n",
    "log_normal = np.array(temp / sum(temp))\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "plt.title(\"CDF (Cumulative Distribution Function)\")\n",
    "samples_g, prob_g = qgan.generator.get_output(qgan.quantum_instance, shots=10000)\n",
    "samples_g = np.array(samples_g)\n",
    "samples_g = samples_g.flatten()\n",
    "num_bins = len(prob_g)\n",
    "plt.bar(samples_g, np.cumsum(prob_g), color=\"royalblue\", width=0.8, label=\"simulation\")\n",
    "plt.plot(\n",
    "    np.cumsum(log_normal), \"-o\", label=\"log-normal\", color=\"deepskyblue\", linewidth=4, markersize=12\n",
    ")\n",
    "plt.xticks(np.arange(min(samples_g), max(samples_g) + 1, 1.0))\n",
    "plt.grid()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"p(x)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-22T01:49:13.439275Z",
     "start_time": "2019-08-22T01:49:13.430311Z"
    }
   },
   "outputs": [],
   "source": [
    "import qiskit.tools.jupyter\n",
    "\n",
    "%qiskit_version_table\n",
    "%qiskit_copyright"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "QiskitDevenv",
   "language": "python",
   "name": "qiskitdevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
