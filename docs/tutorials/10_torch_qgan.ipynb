{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch qGAN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Description\n",
    "A PyTorch-based Quantum Generative Adversarial Network algorithm.\n",
    "\n",
    "The qGAN [1] is a hybrid quantum-classical algorithm used for generative modeling tasks.\n",
    "\n",
    "This adaptive algorithm uses the interplay of a generator given by a parameterized quantum\n",
    "circuit and a discriminator given by a classical neural network to learn the probability\n",
    "distribution underlying given training data.\n",
    "\n",
    "The generator and discriminator are trained in alternating optimization steps, where the\n",
    "generator aims at generating samples which the discriminator classifies as training data\n",
    "samples and the discriminator tries to differentiate between training data samples\n",
    "and data samples from the generator. The final goal is for the quantum generator to learn\n",
    "a representation for the training data's underlying probability distribution.\n",
    "The trained quantum generator can, thus, be used to load a quantum state\n",
    "which is an approximate model of the target distribution.\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Zoufal et al.,\n",
    "    `Quantum Generative Adversarial Networks for learning and loading random distributions\n",
    "    <https://www.nature.com/articles/s41534-019-0223-2>`_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<torch._C.Generator at 0x7f7e20373390>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Necessary imports\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from typing import Union, List, Iterable\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from torch import Tensor, stack, manual_seed\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Adam\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from qiskit import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance, algorithm_globals\n",
    "from qiskit.opflow import Gradient, StateFn\n",
    "from qiskit.circuit.library import TwoLocal\n",
    "from qiskit.circuit import ParameterExpression, ParameterVector\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "from qiskit_machine_learning.datasets.dataset_helper import discretize_and_truncate\n",
    "\n",
    "# Set seed for random generators\n",
    "algorithm_globals.random_seed = 42\n",
    "np.random.seed = 42\n",
    "manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data and Representation\n",
    "\n",
    "First, we need to load our training data $X$. In this tutorial, the training data\n",
    "is given by samples from a 2D multivariate normal distribution.\n",
    "\n",
    "The trained generator corresponds to an $n$-qubit quantum state\n",
    "\\begin{equation}\n",
    "|g_{\\text{trained}}\\rangle=\\sum\\limits_{j=0}^{k-1}\\sqrt{p_{j}}|x_{j}\\rangle,\n",
    "\\end{equation}\n",
    "where the basis states $|x_{j}\\rangle$ represent the data items in the training data set\n",
    "$X={x_0, \\ldots, x_{k-1}}$ with $k\\leq 2^n$ and $p_j$ refers to the sampling probability\n",
    "of $|x_{j}\\rangle$.\n",
    "\n",
    "To facilitate this representation, we need to map the samples from the multivariate\n",
    "normal distribution to discrete values. The number of values that can be represented\n",
    "depends on the number of qubits used for the mapping.\n",
    "Hence, the data resolution is defined by the number of qubits.\n",
    "If we use $3$ qubits to represent one feature, we have 2^3=8 discrete values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Load the training data\n",
    "training_data = np.random.default_rng().multivariate_normal(mean=[0., 0.], cov=[[1, 0], [0, 1]], size=1000, check_valid='warn',\n",
    "                                                        tol=1e-8, method='svd')\n",
    "# Define minimal and maximal values for the training data\n",
    "bounds_min = np.percentile(training_data, 5, axis=0)\n",
    "bounds_max = np.percentile(training_data, 95, axis=0)\n",
    "bounds = []\n",
    "for i, _ in enumerate(bounds_min):\n",
    "    bounds.append([bounds_min[i], bounds_max[i]])\n",
    "\n",
    "# Determine data resolution for each dimension of the training data in terms\n",
    "# of the number of qubits used to represent each data dimension.\n",
    "data_dim = [3, 3]\n",
    "\n",
    "# Pre-processing, i.e., discretization of the data (gridding)\n",
    "(training_data,\n",
    "data_grid,\n",
    "grid_elements,\n",
    "prob_data ) = discretize_and_truncate(\n",
    "training_data,\n",
    "np.array(bounds),\n",
    "data_dim,\n",
    "return_data_grid_elements=True,\n",
    "return_prob=True,\n",
    "prob_non_zero=True,\n",
    ")\n",
    "\n",
    "# Define the training batch size\n",
    "batch_size = 300\n",
    "dataloader = DataLoader(training_data, batch_size=batch_size, shuffle=True, drop_last=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Specify Backend\n",
    "Next, we need to choose a backend that is used to run the quantum generator.\n",
    "The presented method is compatible with all shot-based backends (qasm, fake hardware, real hardware) provided by Qiskit."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "backend = Aer.get_backend('aer_simulator')\n",
    "qi = QuantumInstance(backend, shots = batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "adapted from [PyTorch GAN](https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/gan/gan.py)\n",
    "TODO"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Definition of quantum generator and the respective gradient\n",
    "Next, we define factories that create the quantum generator and a function that calculates the gradients for the quantum generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_generator(qnn: QuantumCircuit,\n",
    "                     parameters: Union[ParameterVector, ParameterExpression, List[ParameterExpression]]) -> TorchConnector:\n",
    "    \"\"\"\n",
    "    Factory to create the quantum generator from a given parameterized quantum circuit.\n",
    "    Args:\n",
    "        qnn: Quantum neural network ansatz given as a quantum circuit.\n",
    "        parameters: The parameters of the quantum neural network which are trained.\n",
    "    Returns:\n",
    "        Quantum neural network compatible with PyTorch\n",
    "    \"\"\"\n",
    "    circuit_qnn = CircuitQNN(qnn, input_params=[], weight_params = parameters,\n",
    "                             quantum_instance=qi, sampling=True, sparse=False,\n",
    "                             input_gradients=True, interpret=lambda x: grid_elements[x])\n",
    "    # We use the Qiskit TorchConnector to ensure compatibility with PyTorch\n",
    "    return TorchConnector(circuit_qnn)\n",
    "\n",
    "def generator_grad(qnn: QuantumCircuit,\n",
    "                   parameters: Union[ParameterVector, ParameterExpression, List[ParameterExpression]],\n",
    "                   param_values: Iterable,\n",
    "                   grad_method: str = 'param_shift') -> Iterable:\n",
    "    \"\"\"\n",
    "    The function returns the gradient values for the quantum generator given the\n",
    "    underlying parameterized quantum circuit.\n",
    "    Args:\n",
    "        qnn: Quantum neural network ansatz given as a quantum circuit.\n",
    "        parameters: The parameters of the quantum neural network which are trained.\n",
    "        param_values: The current values of the quantum neural network parameters.\n",
    "        grad_method: Method used to compute the gradients {'param_shift', 'lin_comb', 'fin_diff'}\n",
    "    Returns:\n",
    "        List of gradients for the sampling probabilities of the quantum neural network.\n",
    "    \"\"\"\n",
    "    grad = Gradient(grad_method=grad_method).gradient_wrapper(StateFn(qnn), parameters, backend=qi)\n",
    "    grad_values = grad(param_values)\n",
    "    return grad_values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Definition of classical discriminator\n",
    "Next, we define factories that create the classical discriminators. The underlying gradients can be automatically computed with PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class create_discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    Factory to create the quantum generator from a given parameterized quantum circuit.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(create_discriminator, self).__init__()\n",
    "\n",
    "        self.Linear_in = nn.Linear(len(data_dim), 20)\n",
    "        self.Leaky_ReLU = nn.LeakyReLU(0.2, inplace=True)\n",
    "        # self.Linear50 = nn.Linear(50, 20)\n",
    "        self.Linear20 = nn.Linear(20, 1)\n",
    "        self.Sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        x = self.Linear_in(input)\n",
    "        x = self.Leaky_ReLU(x)\n",
    "        # x = self.Linear50(x)\n",
    "        # x = self.Leaky_ReLU(x)\n",
    "        x = self.Linear20(x)\n",
    "        x = self.Sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of the quantum neural network ansatz\n",
    "Now, we are ready to define the parameterized quantum circuit $G\\left(\\boldsymbol{\\theta}\\right)$ with $\\boldsymbol{\\theta} = {\\theta_1, ..., \\theta_k}$ which corresponds to our quantum generator.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# sum(data_dim) corresponds to the total number of qubits in our quantum circuit (qc)\n",
    "qc = QuantumCircuit(sum(data_dim))\n",
    "qc.h(qc.qubits)\n",
    "# We choose a hardware efficient ansatz.\n",
    "twolocal = TwoLocal(sum(data_dim), \"ry\", \"cx\", reps=2, entanglement=\"circular\")\n",
    "qc.compose(twolocal, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of the loss functions\n",
    "We want to train the generator and the discriminator with binary cross entropy as loss function:\n",
    "$$L\\left(\\boldsymbol{\\theta}\\right)=\\sum_jp_j\\left(\\boldsymbol{\\theta}\\right)\\left[y_j\\log(x_j) + (1-y_j)\\log(1-x_j)\\right],$$\n",
    "where $x_j$ refers to a data sample and $y_j$ to the corresponding label."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Generator loss function\n",
    "g_loss_fun = nn.BCELoss()\n",
    "# Discriminator loss function\n",
    "d_loss_fun = nn.BCELoss()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Evaluation of custom gradients for the generator BCE loss function\n",
    "The evaluation of custom gradients for the quantum generator requires us to combine quantum gradients $\\frac{\\partial p_j\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_l}$ that we compute with Qiskit's gradient framework with the binary cross entropy as follows:\n",
    "$$\\frac{\\partial L\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_l} = \\sum_j \\frac{\\partial p_j\\left(\\boldsymbol{\\theta}\\right)}{\\partial \\theta_l} \\left[y_j\\log(x_j) + (1-y_j)\\log(1-x_j)\\right].$$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def g_loss_fun_grad(qnn: QuantumCircuit,\n",
    "                    parameters: Union[ParameterVector, ParameterExpression, List[ParameterExpression]],\n",
    "                    param_values: Iterable,\n",
    "                    discriminator_: nn.Module,\n",
    "                    grad_method: str = 'param_shift') -> Iterable:\n",
    "    \"\"\"\n",
    "    Custom gradient of the generator loss function considering the custom gradients of the quantum generator\n",
    "    Args:\n",
    "        qnn: Quantum neural network ansatz given as a quantum circuit.\n",
    "        parameters: The parameters of the quantum neural network which are trained.\n",
    "        param_values: The current values of the quantum neural network parameters.\n",
    "        discriminator_: Classical neural network representing the discriminator.\n",
    "        grad_method: Method used to compute the gradients {'param_shift', 'lin_comb', 'fin_diff'}\n",
    "    Returns:\n",
    "        List of gradient values, i.e., the gradients of the loss function w.r.t. the quantum neural network parameters\n",
    "    \"\"\"\n",
    "    grads = generator_grad(qnn, parameters, param_values, grad_method = grad_method)\n",
    "    loss_grad = ()\n",
    "    for j, grad in enumerate(grads):\n",
    "        cx = grad[0].tocoo()\n",
    "        input = []\n",
    "        target = []\n",
    "        weight = []\n",
    "        for index, prob_grad in zip(cx.col, cx.data):\n",
    "            input.append(grid_elements[index])\n",
    "            target.append([1.])\n",
    "            weight.append([prob_grad])\n",
    "        bce_loss_grad = F.binary_cross_entropy(discriminator_(Tensor(input)), Tensor(target), weight=Tensor(weight))\n",
    "        loss_grad += (bce_loss_grad, )\n",
    "    loss_grad = stack(loss_grad)\n",
    "    return loss_grad"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Relative entropy as benchmarking metric\n",
    "The relative entropy describes a distance metric for distributions. Hence, we can use it to benchmark how close/far away the trained distribution is from the target distribution."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def get_rel_entr(gen_data) -> float:\n",
    "    \"\"\"Get relative entropy between target and trained distribution\"\"\"\n",
    "    prob_gen = np.zeros(len(grid_elements))\n",
    "    for j, item in enumerate(grid_elements):\n",
    "        for gen_item in gen_data.detach().numpy():\n",
    "            if np.allclose(np.round(gen_item, 6), np.round(item, 6), rtol=1e-5):\n",
    "                prob_gen[j] += 1\n",
    "    prob_gen=prob_gen/len(gen_data)\n",
    "    prob_gen = [1e-8 if x == 0 else x for x in prob_gen]\n",
    "    rel_entr = entropy(prob_gen, prob_data)\n",
    "    return rel_entr"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Definition of the optimizers\n",
    "In order to train the generator and discriminator, we need to define optimization schemes. In the following, we employ a momentum based optimizer called Adam [1].\n",
    "\n",
    "**References:**\n",
    "\n",
    "[1] Kingma et al.,\n",
    "    `Adam: A method for stochastic optimization <https://arxiv.org/abs/1412.6980>`_\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = create_generator(qc, twolocal.parameters)\n",
    "discriminator = create_discriminator()\n",
    "\n",
    "lr=0.01 #learning rate\n",
    "b1=0.9 #first momentum parameter\n",
    "b2=0.999 #second momentum parameter\n",
    "n_epochs=1 #number of training epochs\n",
    "\n",
    "#optimizer for the generator\n",
    "optimizer_G = Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n",
    "#optimizer for the discriminator\n",
    "optimizer_D = Adam(discriminator.parameters(), lr=lr, betas=(b1, b2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training\n",
    "Now, we are ready to train our model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'QuantumCircuit' object has no attribute 'ordered_parameters'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-19dd19d2f5ed>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     51\u001B[0m         \u001B[0mg_loss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg_loss_fun\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdiscriminator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgen_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvalid\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m         \u001B[0mg_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mretain_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 53\u001B[0;31m         \u001B[0mg_loss_grad\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mg_loss_fun_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mqc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mqc\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mordered_parameters\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgenerator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdiscriminator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     54\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     55\u001B[0m         \u001B[0mg_loss\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbackward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mretain_graph\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'QuantumCircuit' object has no attribute 'ordered_parameters'"
     ]
    }
   ],
   "source": [
    "# Relative entropy list\n",
    "rel_entr_list = []\n",
    "# Generator loss list\n",
    "g_loss_list = []\n",
    "# Discriminator loss list\n",
    "d_loss_list = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    rel_entr = []\n",
    "    g_loss = []\n",
    "    d_loss = []\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(data.size(0), 1).fill_(1.0), requires_grad=False)\n",
    "        fake = Variable(Tensor(data.size(0), 1).fill_(0.0), requires_grad=False)\n",
    "\n",
    "        # Configure input\n",
    "        real_data = Variable(data.type(Tensor))\n",
    "        # Generate a batch of images\n",
    "        gen_data = generator()\n",
    "\n",
    "        # Evaluate Relative Entropy\n",
    "        rel_entr.append(get_rel_entr(gen_data))\n",
    "\n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "\n",
    "        # Measure discriminator's ability to classify real from generated samples\n",
    "        disc_data = discriminator(real_data)\n",
    "        real_loss = d_loss_fun(disc_data, valid)\n",
    "        fake_loss = d_loss_fun(discriminator(gen_data), fake)  # (discriminator(gen_data).detach(), fake)\n",
    "        d_loss = (real_loss + fake_loss) / 2\n",
    "\n",
    "        # for name, param in discriminator.state_dict().items():\n",
    "        #     print(name, param.detach())\n",
    "\n",
    "        # print('d loss ', d_loss)\n",
    "\n",
    "        d_loss.backward(retain_graph=True)\n",
    "        optimizer_D.step()\n",
    "\n",
    "        # -----------------\n",
    "        #  Train Generator\n",
    "        # -----------------\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # # Loss measures generator's ability to fool the discriminator\n",
    "        g_loss = g_loss_fun(discriminator(gen_data), valid)\n",
    "        g_loss.retain_grad = True\n",
    "        g_loss_grad = g_loss_fun_grad(qc, qc.ordered_parameters, generator.weight.data.numpy(), discriminator)\n",
    "\n",
    "        g_loss.backward(retain_graph=True)\n",
    "        for j, param in enumerate(generator.parameters()):\n",
    "            param.grad = g_loss_grad\n",
    "        optimizer_G.step()\n",
    "\n",
    "        g_loss.append(g_loss.item())\n",
    "        d_loss.append(d_loss.item())\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
    "        )\n",
    "\n",
    "    rel_entr_list.append(np.mean(rel_entr))\n",
    "    g_loss_list.append(np.mean(g_loss))\n",
    "    d_loss_list.append(np.mean(d_loss))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plots\n",
    "Let's visualize what happened during the training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Relative Entropy\n",
    "plt.figure()\n",
    "plt.title('Relative entropy')\n",
    "plt.plot(rel_entr_list)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Relative entropy')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.figure()\n",
    "plt.title('Loss')\n",
    "plt.plot(g_loss_list, label = 'generator loss')\n",
    "plt.plot(d_loss_list, label = 'discriminator loss')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QiskitDevenv",
   "language": "python",
   "name": "qiskitdevenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}